---
title:  "Exploring Models"
type:   content
---

# Sidebar:  passing data between RMarkdown workflows

In the last class you (hopefully) created a table that contained the temperature data over time for both the northern and southern hemispheres.  Today we'll learn some new modeling techniques by exploring this dataset futher.

So, assuming you are creating a new RMarkdown file for each class, what's the easiest way to pass newly created data structures in one markdown to another?  Remember that each RMarkdown Knits in it's own little universe (environment), so the `temps` data from last class won't automatically be available in your new markdown for today.

You have two options.  If the data you want to pass between markdowns is a table the best option is to use a `write.*` function in the source document and a `read.*` function in the destination.  Matching functions are compatible if you use their defaults.  Common options are:

* `write.table` and `read.table`
* `write.csv` and `read.csv`
* `write.delim` and `read.delim`

These functions are nice because they just save the table in plain text with commonly used formatting that is likely to be parsable by other software (Excel, SAS, etc.).  If you have more complicated data structures that you need to save and load in different RMarkdown files, the `saveRDS` and `readRDS` functions are useful; by default they save compressed binary representations of your data. 

Add a line to your RMarkdown from last class like:

```{r eval=FALSE} 
write.table(temps, "data/temperature-by-hemisphere.txt")
```

Note:  this line assumes you have a `data/` subfolder in your current working directory.

Now at the top of today's RMarkdown file you can add a line like this:

```{r}
temps <- read.table("data/temperature-by-hemisphere.txt")
```

Finally, let's load the packages we're going to need today:

```{r}
library(tidyverse)
```

# Visualizing Trends

Make sure you've got a table formatted like this:

```{r}
head(temps)
```

In general, we'd expect the temperature indexes for earth's two hemispheres to be fairly well correlated.  Let's make a visualization that asks this question.  

Here's a fair first shot:

```{r}
ggplot(temps, aes(northern, southern, color = year)) + geom_point()
```

Why did I choose that aesthetic mapping design?

Many of you have already played around with using `geom_smooth` to help highlight trends in plots with lots of points.  We could use it here:

```{r}
ggplot(temps, aes(northern, southern, color = year)) + 
  geom_point() + 
  geom_smooth(method = "loess")
```

I choose [LOESS](https://en.wikipedia.org/wiki/Local_regression) as the `method`, because it's appropriate if we just want to generate a smoothing line based on the local density of our data, without making any other assumptions about relationships between the two axes.

In this case, is the behavior of the smoothing line likely meaningful at the extreme temperature indexes?  Smoothing techniques like this are more useful when you are trying to highlight both local and global trends.  

Let's play with applying it to changes in the temperature of each hemisphere over time.  You'll probably have to create a date column before you continue.  If you've forgotten how this works see the end of [Tidying Data](https://rna.wlu.edu/bio185/10-tidying-data.html):

```{r}
library(lubridate)
temps$date <- make_date(year = temps$year, month = temps$month_n)
```

Now we gather our source table (remind yourself why!) and can make a scatter plot:

```{r}
temps %>%
  gather(key = "hemisphere", value = "index", northern, southern) %>%
  ggplot(aes(date, index, color = hemisphere)) + 
    geom_point(alpha = 0.5)
```

A large width smoothing function (applied using the `span` parameter) can be used to highlight the large trends over time:

```{r}
temps %>%
  gather(key = "hemisphere", value = "index", northern, southern) %>%
  ggplot(aes(date, index, color = hemisphere)) + 
    geom_point(alpha = 0.1) + 
    geom_smooth(method = "loess", span = 0.75)
```

A narrower width smoothing function can be used to pick up annual trends:

```{r}
temps %>%
  gather(key = "hemisphere", value = "index", northern, southern) %>%
  ggplot(aes(date, index, color = hemisphere)) + 
    geom_point(alpha = 0.1) + 
    geom_smooth(method = "loess", span = 0.01)
```

# Modeling

So smoothing functions are useful for highlighting qualitative trends in data, from the local to the global.  But how can we take a more formal approach?

If we return to our comparison of temperatures in each hemisphere, we see a clear relationship (back to the spred-version of our table, of course!):

```{r}
ggplot(temps, aes(northern, southern, color = year)) + geom_point()
```

We can use mathematical models to explore relationships like this one in our data.  One relatively simple, but incredibly powerful, framework for modeling on real data are [linear regression models](https://en.wikipedia.org/wiki/Linear_model).  You've almost certainly generated a linear model before by adding a "trendline" to a scatter plot in Excel.

The easiest way to describe a linear model and fit parameters of that model to a data set is to use the `lm()` function.  There are lots ways to decribe your model; because this is such a common task in statistical analysis, R provides a special syntax for describing models called "formula"'s.  

Above, our plot was setup such that `northern` temperatures are on the independant variable axis, and southern temperatures on the dependent (a.k.a. predictor and response variables, respectively).  The formula syntax describing this relationship would be:

```{r}
lm(southern ~ northern, data = temps)
```

Note the use of the `data` argument to point to the source table where formula variables should be found.

`lm()` is an example of an R function that prints out a few simple things, but is quietly actually returning a complex data structure with a lot of information about our model and it's fit to the data.  Capture that information by assigning the result of a call to `lm()` to a variable:

```{r}
fit <- lm(southern ~ northern, data = temps)
summary(fit)
```

You can see there's a lot more information stored in the return from `lm()` than we see printed out by default.  There are several generic functions that can extract useful values from our `fit`.  For example, `coef()` will give you the coefficients (parameters) for the linear model (y-intercept and slope in this case):

```{r}
coef(fit)
```

We can easily combine this with `geom_abline` to add a line to our scatter plot, showing the result of the linear regression:

```{r}
ggplot(temps, aes(northern, southern, color = year)) + 
  geom_point() +
  geom_abline(slope = coef(fit)[2], intercept = coef(fit)[1])
```

So, there's a compelling trend, but also lots of variation (off-line scatter) between the actual data and our model.  Residuals are the set of values that describe the differences between the value of your function and each data point in the dataset.  The `modelr` package provides a nice function for adding residuals based on a table and a model:

```{r}
library(modelr)
```

```{r eval=FALSE}
add_residuals(temps, fit)
```

```{r echo=FALSE}
head(add_residuals(temps, fit))
```

You can include it in pipes to ggplot of course!  Let's say we want to look at the distribution of our residuals:

```{r}
temps %>%
  add_residuals(fit) %>% #remember why we don't need to specify the table there!
  ggplot(aes(resid)) + geom_histogram()
```

The mean of your residuals should always be 0 if you fit a linear model with least-squares regresssion.

It's very common to also visualize residuals as a function of the response variable:

```{r}
temps %>%
  add_residuals(fit) %>% 
  ggplot(aes(northern, resid)) + geom_point()
```

If you see trends on a plot like this you have a problem.  Shouldn't month affect the relationship between our two variables (why?  Remember how weather works in the two hemispheres!)

```{r}
temps %>%
  add_residuals(fit) %>% 
  ggplot(aes(northern, resid, color = month_n)) + geom_point()
```

What do we see?  That plot treated month as continuous.  Is that right?  Remember you can always switch something to be a categorical variable with the `factor` function:

```{r}
temps %>%
  add_residuals(fit) %>% 
  ggplot(aes(northern, resid, color = factor(month_n))) + geom_point()
```

Do you see any trends?  How about here:

```{r}
temps %>%
  add_residuals(fit) %>% 
  gather(key = "hemisphere", value = "index", northern, southern) %>%
  ggplot(aes(factor(month_n), resid)) + geom_boxplot()
```

We can add month as a predicor variable using either `+` or `*` in our formula syntax.  The first adds independant predictors, the latter evaluates the interaction.

```{r}
fit_month <- lm(southern ~ northern + factor(month_n), data = temps)
summary(fit_month)
```

Now explore plots using your new fit!  Try adding additional possible predictive values from other data sets (*hint*: search the internet for atmosphereic C02 levels!).

